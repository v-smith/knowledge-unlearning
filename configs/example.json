{
    "mode": "unlearn",
    "wandb_project": "Knowledge Unlearning",
    "wandb_run_name": "example",
    "num_train_epochs": 20,
    "check_val_every_n_epoch": 1,
    "check_validation_only": false,
    "do_init_eval": true,
    "train_set": "data/domain_main/enron_emails_8_0.csv",
    "valid_sets": [
        "data/domain_main/enron_emails_8_0.csv",
        "validation_data/lambada.csv"
    ],
    "valid_subset_path": [
        "",
        ""
    ],
    "valid_type_path": [
        "target",
        "test"
    ],
    "train_batch_size": 4,
    "eval_batch_size": 4,
    "gradient_accumulation_steps": 2,
    "ngpu": 1,
    "learning_rate": 5e-5,
    "model_name_or_path": "EleutherAI/gpt-neo-125M",
    "el_threshold": 0.0499,
    "ma_threshold": 0.2994,
    "input_length": 512,
    "output_length": 512,
    "target_length": 200,
    "num_workers": 4,
    "strategy": "deepspeed_stage_2_offload",
    "fp16": true,
    "wandb_log": false
}
